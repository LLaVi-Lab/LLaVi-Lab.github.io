<!DOCTYPE html>
<!-- saved from url=(0032)https://cvlab.postech.ac.kr/lab/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">

<title>LLaVi Lab - Publications</title>

<!-- <link rel="icon" type="image/png" href="./icon/icon.png" sizes="196x196"> -->
<link href="./icon/icon.png" rel="icon">
<link href="./icon/icon.png" rel="apple-touch-icon">

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Audiowide&family=Bungee+Shade&family=Bytesized&display=swap" rel="stylesheet">

<link href='//fonts.googleapis.com/css?family=Open+Sans:400' rel='stylesheet' type='text/css'>
<link href='//fonts.googleapis.com/css?family=Open+Sans:400italic' rel='stylesheet' type='text/css'>
<link href='//fonts.googleapis.com/css?family=Open+Sans:300' rel='stylesheet' type='text/css'>
<link href='//fonts.googleapis.com/css?family=Open+Sans:600' rel='stylesheet' type='text/css'>
<link href='//fonts.googleapis.com/css?family=Open+Sans:600italic' rel='stylesheet' type='text/css'>
<link href='//fonts.googleapis.com/css?family=Exo+2:500' rel='stylesheet' type='text/css'>
<link href='//fonts.googleapis.com/css?family=Exo+2:800' rel='stylesheet' type='text/css'>

<link href="./css/normalize-min.css" rel="stylesheet">
<link href="./css/icomoon-min.css" rel="stylesheet">
<link href="./css/style.css" rel="stylesheet">
<link href="./css/whitecat-slider-min.css" rel="stylesheet">
<link href="./css/responsive.css" rel="stylesheet">

<script type="text/javascript" async="" src="./js/js"></script><script type="text/javascript" async="" src="./js/linkid.js"></script><script async="" src="./js/analytics.js"></script><script async="" src="./js/analytics.js"></script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-51541969-1', 'postech.ac.kr');
  ga('require', 'displayfeatures');
  ga('require', 'linkid', 'linkid.js');
  ga('send', 'pageview');

</script>
</head><body class="js no-touch" style=""><header>
<div class="menu-bg">
<nav class="wrappernav cf">
<a href="https://llavi-lab.github.io/" class="logo cvlab"><h1><strong>LLaVi Lab</strong></h1></a>

<ul class="menu" id="menu">
<li><a href="https://llavi-lab.github.io/" class="link-to-button">Home</a>
<li><a href="./news.html" class="link-to-button">News</a>
</li><li><a href="./people.html" class="link-to-button">People</a>
</li><li><a href="./publication.html" class="link-to-button">Publications</a>
</li><li><a href="./seminar.html" class="link-to-button" target="_blank">Seminar</a>
</li><li><a href="./opening.html" class="link-to-button">Opening</a>
</li><li><a href="./album.html" class="link-to-button">Album</a>

</li></ul><ul class="menu" id="menu-clone" style="display: none;">
<li><a href="https://llavi-lab.github.io/" class="dropdown-item">Home</a>
<li><a href="./news.html" class="dropdown-item">News</a>
</li><li><a href="./people.html" class="dropdown-item">People</a>
</li><li><a href="./publication.html" class="dropdown-item">Publications</a>
</li><li><a href="./seminar.html" class="dropdown-item" target="_blank">Seminar</a>
</li><li><a href="./opening.html" class="dropdown-item">Opening</a>
</li><li><a href="./album.html" class="dropdown-item">Album</a>

</li></ul>
<span class="menu-small icomoon-menu"></span>
</nav>
</div><!-- End .menu-bg -->
</header>



<div class="wrapper cf bd">
  <h1 class="col-1">Selected Publications</h1>
  <h5 class="col-1" style="margin-top: -20px;">(*equal contribution and co-first authors, &dagger;equal advising and co-last authors)</h5>  
  
  <div class="items-1" id="portfolio-items">
  
  
  <!-- publications in 2025 -->
  <div class="item item-year thumb-hover" data-categories="international international-journal international-conference korean">
  <h2 class="portfolio-year">2025</h2>
  </div><!-- END .item .item-year -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
  <h5 class="portfolio-title">RoLocMe: A Robust Multi-agent Source Localization System with Learning-based Map Estimation</h5>
  T. Le, L. Ye, and Y. Huang<br>
  International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>), 2025. <br>
  <a href="#" target="_blank">Paper</a>
  </div><!-- END .item .item-content -->
    
  <div class="item item-content thumb-hover" data-categories="international international-conference">
  <h5 class="portfolio-title">CorrBEV: Multi-View 3D Object Detection by Correlation Learning with Multi-modal Prototypes</h5>
  Z. Xue, M. Guo, H. Fan, S. Zhang, and Z. Zhang<br>
  IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2025. <br>
  <a href="#" target="_blank">Paper</a>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">LaMOT: Language-Guided Multi-Object Tracking</h5>
    Y. Li*, X. Liu*, L. Liu, H. Fan&dagger;, and L. Zhang&dagger;<br>
    IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2025. <br>
    <a href="https://arxiv.org/abs/2406.08324" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="https://github.com/Nathan-Li123/LaMOT" target="_blank" style="color: #37a8d2;">Code-Data</a>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">CGTrack: Cascade Gating Network with Hierarchical Feature Aggregation for UAV Tracking</h5>
    W. Li, X. Liu, H. Fan&dagger;, and L. Zhang&dagger;<br>
    IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2025. <br>
    <a href="./papers/ICRA_2025_CGTrack.pdf" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="https://github.com/Nightwatch-Fox11/CGTrack" target="_blank" style="color: #37a8d2;">Code</a>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">The Devil is in the Quality: Exploring Informative Samples for Semi-Supervised Monocular 3D Object Detection</h5>
    Z. Zhang, Z. Li, H. Wang, H. Yuan, K. Wang, and H. Fan<br>
    IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2025. <br>
    <a href="./papers/icra25-3d-detectopn.pdf" target="_blank" style="color: #37a8d2;">Paper</a> 
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">Knowing Your Target: Target-Aware Transformer Makes Better Spatio-Temporal Video Grounding</h5>
    X. Gu, Y. Shen, C. Luo, T. Luo, Y. Huang, Y. Lin, H. Fan&dagger;, L. Zhang&dagger;<br>
    International Conference on Learning Representations (<b>ICLR</b>), 2025. <br>
    <span class="extra">Oral presentation</span><br>
    <a href="https://arxiv.org/abs/2502.11168" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="https://github.com/HengLan/TA-STVG" target="_blank" style="color: #37a8d2;">Code</a>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">AttMOT: Improving Multiple-Object Tracking by Introducing Auxiliary Pedestrian Attributes</h5>
    Y. Li, Z. Xiao, L. Yang, D. Meng, X. Zhou, H. Fan, and L. Zhang<br>
    IEEE Transactions on Neural Networks and Learning Systems (<b>T-NNLS</b>), 36(3): 5454-5468, 2025. <br>
    <a href="https://arxiv.org/abs/2308.07537" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="https://github.com/HengLan/AttMOT" target="_blank" style="color: #37a8d2;">Code</a>
  </div><!-- END .item .item-content -->


  <!-- publications in 2024 -->
  <div class="item item-year thumb-hover" data-categories="international international-journal international-conference koreanan">
  <h2 class="portfolio-year">2024</h2>
  </div><!-- END .item .item-year -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">DAAP: Privacy-Preserving Model Accuracy Estimation on Unlabeled Datasets Through Distribution-Aware Adversarial Perturbation</h5>
    G. Cao, Z. Wang, Y. Feng, and X. Dong.<br>
    The 33rd USENIX Security Symposium (<b>USENIX Security</b>), 2024.<br>
    <a href="https://www.usenix.org/conference/usenixsecurity24/presentation/cao-guodong" target="_blank" style="color: #37a8d2;">Paper</a>  
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">VastTrack: Vast Category Visual Object Tracking</h5>
    L. Peng*, J. Gao*, X. Liu*, W. Li*, S. Dong*, Z. Zhang, H. Fan&dagger;, and L. Zhang&dagger;<br>
    Advances in Neural Information Processing Systems (<b>NeurIPS</b>), 2024. <br>
    <a href="https://arxiv.org/abs/2403.03493" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="./papers/VastTrack-poster.pdf" target="_blank" style="color: #37a8d2;">Poster</a> &nbsp; <a href="https://github.com/HengLan/VastTrack" target="_blank" style="color: #37a8d2;">Code-Data</a>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">Optical Flow as Spatial-Temporal Attention Learners</h5>
    Y. Lu, C. Han, Q. Wang, H. Fan, Z. Kong, D. Liu, and Y. Chen<br>
    IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>PAMI</b>), 46(12): 11491-11506, 2024.<br>
    <a href="https://ieeexplore.ieee.org/document/10705000" target="_blank" style="color: #37a8d2;">Paper</a>  
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">Cyclic Refiner: Object-Aware Temporal Representation Learning for Multi-View 3D Detection and Tracking</h5>
    M. Guo, Z. Zhang, L. Jing, Y. He, K. Wang, and H. Fan<br>
    International Journal of Computer Vision (<b>IJCV</b>), 132: 6184–6206, 2024.<br>
    <a href="https://arxiv.org/abs/2407.03240" target="_blank" style="color: #37a8d2;">Paper</a>  
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">Beyond MOT: Semantic Multi-Object Tracking</h5>
    Y. Li, Q. Li, H. Wang, X. Ma, J. Yao, S. Dong, H. Fan&dagger;, and L. Zhang&dagger;<br>
    European Conference on Computer Vision (<b>ECCV</b>), 2024.<br>
    <a href="https://arxiv.org/abs/2403.05021" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp; <a href="https://github.com/HengLan/SMOT" target="_blank" style="color: #37a8d2;">Code-Data</a> 
    <br>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">Tracking Meets LoRA: Faster Training, Larger Model, Stronger Performance</h5>
    L. Lin, H. Fan, Z. Zhang, Y. Wang, Y. Xu, and H. Ling<br>
    European Conference on Computer Vision (<b>ECCV</b>), 2024.<br>
    <a href="https://arxiv.org/abs/2403.05231" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp; <a href="https://github.com/LitingLin/LoRAT" target="_blank" style="color: #37a8d2;">Code</a> 
    <br>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">Efficient Multimodal Semantic Segmentation via Dual-Prompt Learning</h5>
    S. Dong, Y. Feng, Q. Yang, Y. Huang, D. Liu, and H. Fan<br>
    IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS</b>), 2024.<br>
    <span class="extra">Oral presentation</span><br>
    <a href="https://arxiv.org/abs/2312.00360" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp; <a href="https://github.com/ShaohuaDong2021/DPLNet" target="_blank" style="color: #37a8d2;">Code</a> 
    <br>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">SiCP: Simultaneous Individual and Cooperative Perception for 3D Object Detection in Connected and Automated Vehicles</h5>
    D. Qu, Q. Chen, T. Bai, A. Qin, H. Lu, H. Fan, S. Fu, and Q. Yang<br>
    IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS</b>), 2024.<br>
    <span class="extra">Oral presentation</span><br>
    <a href="https://arxiv.org/abs/2312.04822" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp; <a href="https://github.com/DarrenQu/SiCP" target="_blank" style="color: #37a8d2;">Code</a> 
    <br>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">Robust Domain Adaptive Object Detection with Unified Multi-Granularity Alignment</h5>
    L. Zhang, W. Zhou, H. Fan&Dagger;, T. Luo, and H. Ling (&Dagger;<b>corresponding author</b>)<br>
    IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>PAMI</b>), 46(12): 9161-9178, 2024.<br>
    <a href="https://arxiv.org/abs/2301.00371" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp; <a href="https://github.com/tiankongzhang/MGA" target="_blank" style="color: #37a8d2;">Code</a> 
    <br>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">Divert More Attention to Vision-Language Object Tracking</h5>
    M. Guo, Z. Zhang, L. Jing, H. Ling, and H. Fan<br>
    IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>PAMI</b>), 46(12): 8600-8618, 2024.<br>
    <a href="https://arxiv.org/abs/2307.10046" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp; <a href="https://github.com/JudasDie/SOTS" target="_blank" style="color: #37a8d2;">Code</a> 
    <br>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">Context-Guided Spatio-Temporal Video Grounding</h5>
    X. Gu*, H. Fan*, Y. Huang, T. Luo, and L. Zhang<br>
    IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024.<br>
    <a href="https://arxiv.org/abs/2401.01578" target="_blank" style="color: #37a8d2;">Paper</a> &nbsp; <a href="https://hengfan2010.github.io/publication/CG-STVG-CVPR24-poster.pdf" target="_blank" style="color: #37a8d2;">Poster</a>  &nbsp; <a href="https://github.com/HengLan/CGSTVG" target="_blank" style="color: #37a8d2;">Code</a> 
    <br>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">ProMotion: Prototypes As Motion Learners</h5>
    Y. Lu, D. Liu, Q. Wang, C. Han, Y. Cui, Z. Cao, X. Zhang, Y. Chen, and H. Fan<br>
    IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024.<br>
    <a href="https://arxiv.org/abs/2406.04999" target="_blank" style="color: #37a8d2;">Paper</a> 
    <br>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">Kernel Adaptive Convolution for Scene Text Detection via Distance Map Prediction</h5>
    J. Zheng, H. Fan, and L. Zhang<br>
    IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024.<br>
    <a href="https://hengfan2010.github.io/publication/Text_detection_CVPR_2024_paper.pdf" target="_blank" style="color: #37a8d2;">Paper</a> 
    <br>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">CereSZ: Enabling and Scaling Error-bounded Lossy Compression on Cerebras CS-2</h5>
    S. Song, Y. Huang, P. Jiang, X. Yu, W. Zheng, S. Di, Q. Cao, Y. Feng, Z. Xie, and F. Cappello<br>
    ACM International Symposium on High-Performance Parallel and Distributed Computing (<b>HPDC</b>), 2024.<br>
    <a href="https://dl.acm.org/doi/10.1145/3625549.3658691" target="_blank" style="color: #37a8d2;">Paper</a> 
    <br>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">MaGIC: Multi-modality Guided Image Completion</h5>
    H. Wang*, Y. Yu*, T. Luo, H. Fan, and L. Zhang<br>
    International Conference on Learning Representations (<b>ICLR</b>), 2024.<br>
    <a href="https://arxiv.org/abs/2305.11818" target="_blank" style="color: #37a8d2;">Paper</a> &nbsp; <a href="http://www.yongshengyu.com/MaGIC-Page/" target="_blank" style="color: #37a8d2;">Code</a> 
    <br>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">Local Compressed Video Stream Learning for Generic Event Boundary Detection</h5>
    L. Zhang, X. Gu, C. Li, T. Luo, and H. Fan<br>
    International Journal of Computer Vision (<b>IJCV</b>), 132: 1187-1204, 2024.<br>
    <a href="https://arxiv.org/abs/2309.15431" target="_blank" style="color: #37a8d2;">Paper</a> &nbsp; <a href="https://github.com/GX77/LCVSL" target="_blank" style="color: #37a8d2;">Code</a> 
    <br>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">PreciseDebias: An Automatic Prompt Engineering Approach for Generative AI to Mitigate Image Demographic Biases</h5>
    C. Clemmer, J. Ding, and Y. Feng.<br>
    IEEE/CVF Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2024.<br>
    <a href="https://yunhefeng.me/material/WACV-2024.pdf" target="_blank" style="color: #37a8d2;">Paper</a> &nbsp; <a href="https://github.com/ResponsibleAILab/Precise_Debias" target="_blank" style="color: #37a8d2;">Code</a> 
    <br>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">SSPNet: Scale and Spatial Priors Guided Generalizable and Interpretable Pedestrian Attribute Recognition</h5>
    J. Shen, T. Guo, X. Zuo, H. Fan, and W. Yang<br>
    Pattern Recognition (<b>PR</b>), 148: 110194, 2024.<br>
    <a href="https://arxiv.org/abs/2312.06049" target="_blank" style="color: #37a8d2;">Paper</a> 
    <br>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">ICAFusion: Iterative Cross-Attention Guided Feature Fusion for Multispectral Object Detection</h5>
    J. Shen, Y. Chen, Y. Liu, X. Zuo, H. Fan, and W. Yang<br>
    Pattern Recognition (<b>PR</b>), 145: 109913, 2024.<br>
    <a href="https://arxiv.org/abs/2308.07504" target="_blank" style="color: #37a8d2;">Paper</a> &nbsp; <a href="https://github.com/chanchanchan97/ICAFusion" target="_blank" style="color: #37a8d2;">Code</a> 
    <br>
  </div><!-- END .item .item-content -->

  <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">Task-Free Fairness-Aware Bias Mitigation for Black-Box Deployed Models</h5>
    G. Cao, Z. Wang, Y. Feng, X. Dong, Z. Zhang, Z. Qin, and K. Ren<br>
    IEEE Transactions on Dependable and Secure Computing (<b>TDSC</b>), 21: 3390-3405, 2024.<br>
    <a href="https://ieeexplore.ieee.org/document/10301678" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp; 
  </div><!-- END .item .item-content -->

  <!-- publications in 2023 -->
  <div class="item item-year thumb-hover" data-categories="international international-journal international-conference korean">
    <h2 class="portfolio-year">2023</h2>
    </div><!-- END .item .item-year -->
  
    <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">A Multi-granularity Decade-Long Geo-Tagged Twitter Dataset for Spatial Computing</h5>
    Y. Feng, Z. Meng, C. Clemmer, H. Fan, and Y. Huang<br>
    ACM International Conference on Advances in Geographic Information Systems (<b>SIGSPATIAL</b>), 2023. <br>
    <a href="https://hengfan2010.github.io/publication/SIGSPATIAL-2023.pdf" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="https://sigspatial.yunhefeng.me/" target="_blank" style="color: #37a8d2;">Data</a>
    </div><!-- END .item .item-content -->
  
    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">PIDray: A Large-scale X-ray Benchmark for Real-World Prohibited Item Detection</h5>
      L. Zhang, L. Jiang, R. Ji, and H. Fan<br>
      International Journal of Computer Vision (<b>IJCV</b>), 131: 3170-3192, 2023. <br>
      <a href="https://arxiv.org/abs/2211.10763" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="https://github.com/lutao2021/PIDray" target="_blank" style="color: #37a8d2;">Code-Data</a>
    </div><!-- END .item .item-content -->

    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">Towards Transferable Targeted Adversarial Examples</h5>
      Z. Wang, H. Yang, Y. Feng, P. Sun, H. Guo, Z. Zhang, and K. Ren<br>
      onference on Computer Vision and Pattern (<b>CVPR</b>), 2023. <br>
      <a href="https://yunhefeng.me/lab/common_files/towards_transferable_targeted.pdf" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp; 
    </div><!-- END .item .item-content -->

    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">Addressing Weak Decision Boundaries in Image Classification by Leveraging Web Search and Generative Models</h5>
      P. Dammu, Y. Feng and C. Shah<br>
      International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), 2023. <br>
      <a href="https://yunhefeng.me/material/IJCAI-2023.pdf" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp; 
    </div><!-- END .item .item-content -->

    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">Collaborative Three-Stream Transformers for Video Captioning</h5>
      H. Wang, L. Zhang, H. Fan, and T. Luo<br>
      Computer Vision and Image Understanding (<b>CVIU</b>), 235: 103799, 2023.<br>
      <a href="https://hengfan2010.github.io/publication/CVIU-COST-23.pdf" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="https://github.com/wanghao14/COST" target="_blank" style="color: #37a8d2;">Code</a>
    </div><!-- END .item .item-content -->

    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">Unsupervised Domain Adaptive Detection with Network Stability Analysis</h5>
      W. Zhou*, H. Fan*, T. Luo, and L. Zhang<br>
      IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023.<br>
      <a href="https://arxiv.org/pdf/2308.08182.pdf" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="https://github.com/tiankongzhang/NSA" target="_blank" style="color: #37a8d2;">Code</a>
    </div><!-- END .item .item-content -->

    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">Two Birds, One Stone: A Unified Framework for Joint Learning of Image and Video Style Transfers</h5>
      B. Gu, H. Fan, and L. Zhang<br>
      IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023.<br>
      <a href="https://arxiv.org/abs/2304.11335" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="https://github.com/NevSNev/UniST" target="_blank" style="color: #37a8d2;">Code</a>
    </div><!-- END .item .item-content -->

    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">Accurate and Fast Compressed Video Captioning</h5>
      Y. Shen, X. Gu, K. Xu, H. Fan, L. Wen, and L. Zhang<br>
      IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023.<br>
      <a href="https://arxiv.org/abs/2309.12867" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="https://github.com/acherstyx/CoCap" target="_blank" style="color: #37a8d2;">Code</a>
    </div><!-- END .item .item-content -->

    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">PlanarTrack: A Large-scale Challenging Benchmark for Planar Object Tracking</h5>
      X. Liu*, X. Liu*, Z. Yi*, X. Zhou*, T. Le, L. Zhang, Y. Huang, Q. Yang, and H. Fan<br>
      IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023.<br>
      <a href="https://arxiv.org/abs/2303.07625" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="https://hengfan2010.github.io/projects/PlanarTrack/" target="_blank" style="color: #37a8d2;">Code</a>
    </div><!-- END .item .item-content -->

    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">Towards Fairness-aware Adversarial Network Pruning</h5>
      L. Zhang, Z. Wang, X. Dong, Y. Feng, X. Pang, Z. Zhang, and K. Ren<br>
      IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023.<br>
      <a href="https://yunhefeng.me/material/ICCV-2023.pdf" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp; 
    </div><!-- END .item .item-content -->

    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">AnimalTrack: A Benchmark for Multi-Animal Tracking in the Wild</h5>
      L. Zhang*, J. Gao*, Z. Xiao, and H. Fan<br>
      International Journal of Computer Vision (<b>IJCV</b>), 131: 496-513, 2023.<br>
      <a href="https://arxiv.org/abs/2205.00158" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="https://hengfan2010.github.io/projects/AnimalTrack/" target="_blank" style="color: #37a8d2;">Code</a>
    </div><!-- END .item .item-content -->

    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">FZ-GPU: A Fast and High-Ratio Lossy Compressor for Scientific Computing Applications on GPUs</h5>
      B. Zhang, J. Tian, S. Di, X. Yu, Y. Feng, X. Liang, D. Tao, F. Cappello<br>
      ACM International Symposium on High-Performance Parallel and Distributed Computing (<b>HPDC</b>), 2023.<br>
      <a href="https://arxiv.org/abs/2304.12557" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;
    </div><!-- END .item .item-content -->

    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">Investigating Code Generation Performance of ChatGPT with Crowdsourcing Social Data</h5>
      Y. Feng, S. Vanam, M. Cherukupally, W. Zheng, M. Qiu and H. Chen<br>
      47th IEEE Computer Software and Applications Conference (<b>COMPSAC</b>), 2023.<br>
      <span class="extra2">Best Track Paper Award</span><br>
      <a href="https://yunhefeng.me/material/ChatGPT-Coding-CompSac-23.pdf" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp; <a href="https://yunhefeng.me/research/Compsac_ChatGPT_Python_Prompt_Code/" target="_blank" style="color: #37a8d2;">Data</a> 
    </div><!-- END .item .item-content -->

    <!-- publications in 2022 -->
    <div class="item item-year thumb-hover" data-categories="international international-journal international-conference korean">
    <h2 class="portfolio-year">2022</h2>
    </div><!-- END .item .item-year -->
  
    <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">SwinTrack: A Simple and Strong Baseline for Transformer Tracking</h5>
    L. Lin*, H. Fan*, Z. Zhang, Y. Xu, and H. Ling<br>
    Advances in Neural Information Processing Systems (<b>NeurIPS</b>), 2022. <br>
    <a href="https://hengfan2010.github.io/publication/SwinTrack-NeurIPS-2022.pdf" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="https://github.com/HengLan/SwinTrack" target="_blank" style="color: #37a8d2;">Code</a>
    </div><!-- END .item .item-content -->

    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">Divert More Attention to Vision-Language Tracking</h5>
      M. Guo*, Z. Zhang*, H. Fan, and L. Jing<br>
      Advances in Neural Information Processing Systems (<b>NeurIPS</b>), 2022. <br>
      <a href="https://hengfan2010.github.io/publication/VLT-NeurIPS-2022.pdf" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="https://github.com/JudasDie/SOTS" target="_blank" style="color: #37a8d2;">Code</a>
    </div><!-- END .item .item-content -->

    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">High-Fidelity Image Inpainting with GAN Inversion</h5>
      Y. Yu, L. Zhang, H. Fan, and T. Luo<br>
      European Conference on Computer Vision (<b>ECCV</b>), 2022.<br>
      <a href="https://hengfan2010.github.io/publication/InvertFill-ECCV-2022.pdf" target="_blank" style="color: #37a8d2;">Paper</a> 
    </div><!-- END .item .item-content -->

    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">Towards Bridging the Distribution Gap: Instance to Prototype Earth Mover’s Distance for Distribution Alignment</h5>
      Q. Zhou, R. Wang, G. Zeng, H. Fan, and G. Zheng<br>
      Medical Image Analysis (<b>MedIA</b>), 82: 102607, 2022.<br>
      <a href="https://hengfan2010.github.io/publication/MedIA-2022.pdf" target="_blank" style="color: #37a8d2;">Paper</a> 
    </div><!-- END .item .item-content -->

    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">Detection and Tracking Meet Drones Challenge</h5>
      P. Zhu, L. Wen, D. Du, X. Bian, H. Fan, Q. Hu, and H. Ling<br>
      IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>PAMI</b>), 44(11): 7380-7399, 2022.<br>
      <a href="https://arxiv.org/abs/2001.06303" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="https://github.com/VisDrone/VisDrone-Dataset" target="_blank" style="color: #37a8d2;">Data</a>
    </div><!-- END .item .item-content -->

    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">GL-GAN: Adaptive Global and Local Bilevel Optimization for Generative Adversarial Network</h5>
      Y. Liu, H. Fan, X. Yuan, and J. Xiang<br>
      Pattern Recognition (<b>PR</b>), 123: 108375, 2022.<br>
      <a href="https://hengfan2010.github.io/publication/PR-22.pdf" target="_blank" style="color: #37a8d2;">Paper</a> 
    </div><!-- END .item .item-content -->

    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">Learning Target-aware Representation for Visual Tracking via Informative Interactions</h5>
      M. Guo, Z. Zhang, H. Fan, L. Jing, Y. Lyu, B. Li, and W. Hu<br>
      International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), 2022.<br>
      <span class="extra">Oral presentation</span><br>
      <a href="https://arxiv.org/abs/2201.02526" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="https://github.com/JudasDie/SOTS" target="_blank" style="color: #37a8d2;">Code</a>
    </div><!-- END .item .item-content -->

    <!-- publications in 2021 -->
    <div class="item item-year thumb-hover" data-categories="international international-journal international-conference korean">
    <h2 class="portfolio-year">2021</h2>
    </div><!-- END .item .item-year -->
  
    <div class="item item-content thumb-hover" data-categories="international international-conference">
    <h5 class="portfolio-title">Transparent Object Tracking Benchmark</h5>
    H. Fan, H. Miththanthaya, Harshit, S. Rajan, X. Liu, Z. Zou, Y. Lin, and H. Ling<br>
    IEEE International Conference on Computer Vision (<b>ICCV</b>), 2021.<br>
    <a href="https://arxiv.org/abs/2011.10875" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="https://hengfan2010.github.io/projects/TOTB/" target="_blank" style="color: #37a8d2;">Code-Data</a>
    </div><!-- END .item .item-content -->

    <div class="item item-content thumb-hover" data-categories="international international-conference">
      <h5 class="portfolio-title">CRACT: Cascaded Regression-Align-Classification for Robust Visual Tracking</h5>
      H. Fan and H. Ling<br>
      IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS</b>), 2021.<br>
      <a href="https://arxiv.org/abs/2011.12483" target="_blank" style="color: #37a8d2;">Paper</a>  &nbsp;  <a href="#" target="_blank" style="color: #37a8d2;">Project</a>
    </div><!-- END .item .item-content -->


  </div><!-- End .items-1 -->
  </div><!-- End .wrapper -->



<footer>
<div class="theme-other footer">
<div class="wrapper cf">
<div class="emblem-wrapper col-1-3">
<div class="emblem-container">
<div class="emblem">
<img height="40" src="./images/unt-gray.png" alt="POSTECH emblem">
</div>
COLLEGE OF ENGINEERING, UNIVERSITY OF NORTH TEXAS<br>
Department&nbsp;of&nbsp;Computer Science and Engineering
</div>
</div><!-- End .col-1-3-->
<div class="col-1-3" style="text-align: center">
<span class="cvlab"><strong>Learning</strong>&nbsp;·&nbsp;<strong>Language</strong>&nbsp;·&nbsp;<strong>Vision</strong> Lab</span>, Department of Computer Science and Engineering, UNT Discovery Park 3940 N. Elm Street, Denton, TX 76207
</div><!-- End .col-1-3-->
<div class="col-1-3" style="text-align: right">
  Copyright &copy; LLaVI Lab, Dept. of CSE, UNT, 2025-Current. All Rights Reserved. <br>
  Our lab website is designed based on <a href="https://cvlab.postech.ac.kr/lab/index.php" target="_blank" style="color: #B3B3B3;">this great template</a>.
</div>
<!-- <div class="col-1-3 badges">
<a href="http://www.w3.org/html/logo/">
<img src="./Computer Vision Lab. POSTECH_files/html5-badge-h-css3-semantics.png" width="82" height="32" alt="HTML5 Powered with CSS3 / Styling, and Semantics" title="HTML5 Powered with CSS3 / Styling, and Semantics">
</a>
<a href="http://jigsaw.w3.org/css-validator/check/referer">
<img src="./Computer Vision Lab. POSTECH_files/valid-css.png" width="88" height="32" alt="Valid CSS!" title="Valid CSS!">
</a>
<a href="http://www.w3.org/WAI/WCAG2AA-Conformance" title="Explanation of WCAG 2.0 Level Double-A Conformance">
<img src="./Computer Vision Lab. POSTECH_files/wcag2AA.png" width="88" height="32" alt="Level Double-A conformance, W3C WAI Web Content Accessibility Guidelines 2.0">
</a>
<a href="http://cvlab.postech.ac.kr:8080/" title="POSTECH CVLab Overlaef (Only Lab member available)">
<img src="./Computer Vision Lab. POSTECH_files/overleaf_gray.png" width="32" height="32" alt="POSTECH CVLab Overleaf Page. Only Lab member is available"></a>
<a href="https://cvlab.postech.ac.kr/wiki" title="POSTECH CVLab WIKI Page (Only Lab member available)">
<img src="./Computer Vision Lab. POSTECH_files/wiki_gray.png" width="32" height="32" alt="POSTECH CVLab WIKI Page. Only Lab member is available"></a>
<a href="http://cvlab.postech.ac.kr:3000/" title="POSTECH CVLab Rocket.chat">
<img src="./Computer Vision Lab. POSTECH_files/rocket_gray.png" width="32" height="32" alt="POSTECH CVLab Rocket.chat. Only Lab member is available"></a>
</div> -->
<!-- End .col-1-3-->
</div><!-- End .wrapper -->
</div><!-- End .theme-other .footer -->
</footer>

<!-- JavaScript -->
<script src="./js/jquery-1.10.2.min.js"></script>
<script src="./js/jquery-whitecat-menu.js"></script>
<script src="./js/jquery-whitecat-slider.min.js"></script>
<script src="./js/jquery-whitecat-accordion.js"></script>
<script src="./js/jquery.isotope.min.js"></script>
<script src="./js/script.js"></script>
</div></div></div></body></html>
